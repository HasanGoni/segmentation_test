# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/07_tf_model_creation.ipynb.

# %% auto 0
__all__ = ['pooling', 'conv_block', 'double_conv', 'encoder_block', 'crop_and_concat', 'decoder_block', 'unet_model',
           'unet_gating_signal', 'expend_as', 'attention_blocks', 'decoder_block_attention_gates',
           'unet_model_attention_gates', 'res_double_conv', 'residual_encoder_block', 'residual_decoder_block',
           'residual_attn_unet']

# %% ../nbs/07_tf_model_creation.ipynb 3
import tensorflow as tf
import numpy as np
import pandas as pd
from fastcore.all import *
from fastcore.test import *
from pathlib import Path
from typing import List, Tuple, Dict, Union, Callable, Optional
from tensorflow.keras import backend as K
import os

# %% ../nbs/07_tf_model_creation.ipynb 6
def pooling(
        inputs,
        max_pool_only=False,
        both=True,
        pool_size=2):
    if both:
        p1 = tf.keras.layers.MaxPooling2D(
            (pool_size, pool_size))(inputs)
        p2 = tf.keras.layers.AvgPool2D(
            pool_size=(pool_size, pool_size))(inputs)
        return tf.keras.layers.concatenate([p1, p2])
    elif max_pool_only:
        return tf.keras.layers.MaxPooling2D(
            (pool_size, pool_size))(inputs)
    else:
        return tf.keras.layers.AvgPool2D(
            pool_size=(pool_size, pool_size))(inputs)
            


# %% ../nbs/07_tf_model_creation.ipynb 7
def conv_block(
        inputs, 
        filter_no, 
        kernel_size, 
        batch_nm=True, 
        dropout=True, 
        drp_rt=0.1,
        kernel_initializer='glorot_normal' #option he_normal
        ):
    'Create a conv block with batch norma and dropout'
    c1 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='glorot_normal',
        padding='same',
        activation=None)(inputs)
    if batch_nm:
        c1 = tf.keras.layers.BatchNormalization()(c1)
    c1 = tf.keras.layers.Activation('relu')(c1)
    if dropout:
        c1 = tf.keras.layers.Dropout(drp_rt)(c1)
    return c1

# %% ../nbs/07_tf_model_creation.ipynb 9
def double_conv(
        inputs, 
        filter_no, 
        kernel_size, 
        batch_nm=True, 
        dropout=True, 
        drp_rt=0.1,
        kernel_initializer='glorot_normal' #option he_normal
        ):
    'Create double conv block with batch norma and dropout'

    c1 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='glorot_normal',
        padding='same',
        activation=None)(inputs)
    if batch_nm:
        c1 = tf.keras.layers.BatchNormalization()(c1)
    c1 = tf.keras.layers.Activation('relu')(c1)
    if dropout:
        c1 = tf.keras.layers.Dropout(drp_rt)(c1)
    c2 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='glorot_normal',
        padding='same',
        activation=None)(c1)
    if batch_nm:
        c2 = tf.keras.layers.BatchNormalization()(c2)
    c2 = tf.keras.layers.Activation('relu')(c2)
    if dropout:
        c2 = tf.keras.layers.Dropout(drp_rt)(c2)
    return c2

# %% ../nbs/07_tf_model_creation.ipynb 13
def encoder_block(
        input_size:tf.Tensor,
        filter_size:List[int]=[16,32,64,128,256],
        kernel_initializer:str='glorot_normal' #option he_normal
                 ):
    'Create Encoder block for Unet'

    inputs = tf.keras.layers.Input(input_size)
    outputs = []
    p = inputs 
    

    for i in filter_size:
        c = double_conv(
            inputs=p, 
            filter_no=i, 
            kernel_size=3, 
            batch_nm=True, 
            dropout=True, 
            drp_rt=0.1,
            kernel_initializer='glorot_normal' #option he_normal
            )
        p = pooling(c, both=True)
        outputs.append(c)

    final_filter_size = filter_size[-1]*2
    final_layer = double_conv(
        inputs=p, 
        filter_no=final_filter_size, 
        kernel_size=3, 
        batch_nm=True, 
        dropout=True, 
        drp_rt=0.1,
        kernel_initializer='glorot_normal' #option he_normal
        )
    #outputs.append(final_layer)
    return inputs, outputs, final_layer

# %% ../nbs/07_tf_model_creation.ipynb 20
def crop_and_concat(upsampled: tf.Tensor, skip_connection: tf.Tensor) -> tf.Tensor:
    """
    Crop or pad the skip connection and concatenate it with the upsampled tensor.
    Args:
    - upsampled (tf.Tensor): Tensor from the decoder path.
    - skip_connection (tf.Tensor): Corresponding tensor from the encoder path.
    Returns:
    - tf.Tensor: Tensor after cropping or padding and concatenation.
    """
    skip_shape = skip_connection.shape[1:3]
    upsample_shape = upsampled.shape[1:3]

    # Calculate difference in shapes and determine if cropping or padding is needed
    height_diff = skip_shape[0] - upsample_shape[0]
    width_diff = skip_shape[1] - upsample_shape[1]

    if height_diff > 0 or width_diff > 0:
        print(f' Cropping branch')
        # Cropping the skip connection
        crop_height = height_diff // 2
        crop_width = width_diff // 2
        cropped_skip_connection = skip_connection[:, 
                                                  crop_height: crop_height + upsample_shape[0], 
                                                  crop_width: crop_width + upsample_shape[1], 
                                                  :]
        return tf.keras.layers.concatenate([upsampled, cropped_skip_connection], axis=-1)
    elif height_diff < 0 or width_diff < 0:

        print(f' Padding branch')
        # Padding the upsampled tensor
        pad_height = -height_diff // 2
        pad_width = -width_diff // 2
        padded_upsampled = tf.pad(upsampled, 
                                  [
                                      [0, 0], 
                                      [pad_height, pad_height], 
                                      [pad_width, pad_width], 
                                      [0, 0]
                                      ], 
                                  mode='constant', constant_values=0)
        return tf.keras.layers.concatenate([padded_upsampled, skip_connection], axis=-1)
    else:
        # Shapes match, direct concatenation
        return tf.keras.layers.concatenate([upsampled, skip_connection], axis=-1)



# %% ../nbs/07_tf_model_creation.ipynb 23
def decoder_block(
    filter_list:List[int],
    encoder_outputs:List[tf.Tensor],
    bottleneck:tf.Tensor,
   ):
    'Create a decoder block for unet'

    filter_list = filter_list[::-1]
    encoder_outputs = encoder_outputs[::-1]


    decoder_output_list = []
    x = bottleneck


    for i, filter_no in enumerate(filter_list):

        #upsample
        x = tf.keras.layers.Conv2DTranspose(
                                            filter_no,
                                            (2,2),
                                            strides=(2,2),
                                            padding='same',
                                            )(x)
        encoder_output = encoder_outputs[i]
        #print(f'encoder_output.shape: {encoder_output.shape}')
        
        # Handle the shape mismatch (if any)
        ################################################################################
        x = crop_and_concat(x, encoder_output)
        ################################################################################



        # Concatenate the upsampled feature map with the corresponding encoder feature map
        decoder_output_list.append(x)

        x = double_conv(
            inputs=x, 
            filter_no=filter_no, 
            kernel_size=3, 
            batch_nm=True, 
            dropout=True, 
            drp_rt=0.1,
            kernel_initializer='glorot_normal' #option he_normal
            )
    return x, decoder_output_list


    



# %% ../nbs/07_tf_model_creation.ipynb 27
def unet_model(
    input_size:Tuple[int]=(1152, 1632, 1),
    filter_list:List[int]=[16,32,64,128],
    kernel_initializer:str='glorot_normal', #option he_normal
    n_classes:int=1
    ):
    'Create a unet model'
    inputs,enc_outputs, final_l = encoder_block(
        input_size=input_size,
        filter_size=filter_list,
        kernel_initializer=kernel_initializer
        )
    final_output, decoder_outputs = decoder_block(
        filter_list=filter_list,
        encoder_outputs=enc_outputs,
        bottleneck=final_l
        )
    if n_classes <=1:   
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='sigmoid')(final_output)
    else:   
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='softmax')(final_output)
    return tf.keras.models.Model(inputs=inputs, outputs=final_output)


# %% ../nbs/07_tf_model_creation.ipynb 31
def unet_gating_signal(
                     input:tf.Tensor,
                     out_size:int,
                     is_batchnorm:bool,
                    name:str,
                    kinit:str='glorot_normal',
                    ):
    ' this is simply 1x1 convolution, bn, activation '

    shape = K.int_shape(input)
    x = tf.keras.layers.Conv2D(
        out_size, (1, 1), strides=(1, 1), padding="same",  
        kernel_initializer=kinit, name=name + '_conv')(input)
    if is_batchnorm:
        x = tf.keras.layers.BatchNormalization(name=name + '_bn')(x)
    x = tf.keras.layers.Activation('relu', name = name + '_act')(x)
    return x

# %% ../nbs/07_tf_model_creation.ipynb 32
def expend_as(tensor, rep,name):
	my_repeat = tf.keras.layers.Lambda(lambda x, repnum: K.repeat_elements(
		                                                 x, 
														 repnum, 
														 axis=3), 
														 arguments={'repnum': rep},  
														 name='psi_up'+name)(tensor)
	return my_repeat

# %% ../nbs/07_tf_model_creation.ipynb 33
def attention_blocks(x, g, inter_shape, name):
    ''' take g which is the spatially smaller signal, do a conv to get the same
    number of feature channels as x (bigger spatially)
    do a conv on x to also get same feature channels (theta_x)
    then, upsample g to be same size as x 
    add x and g (concat_xg)
    relu, 1x1 conv, then sigmoid then upsample the final - this gives us attn coefficients'''
    
    shape_x = K.int_shape(x)
    shape_g = K.int_shape(g)

    # getting x to the same shape as gating signal g
    theta_x = tf.keras.layers.Conv2D(
                                     inter_shape, 
                                     (2, 2), 
                                     strides=(2, 2), 
                                     padding='same', 
                                     name='xl'+name)(x)

    shape_theta_x = K.int_shape(theta_x)

    # getting the gating signal to the same number of feature channels as inter_shape
    phi_g = tf.keras.layers.Conv2D(
                                   inter_shape,
                                   (1, 1),
                                   padding='same')(g)

    upsample_g = tf.keras.layers.Conv2DTranspose(
                                          inter_shape,
                                          (3, 3),
                                          strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),
                                          padding='same', 
                                          name='g_up'+name)(phi_g)

    concat_xg = tf.keras.layers.add([upsample_g, theta_x])
    act_xg = tf.keras.layers.Activation('relu')(concat_xg)

    psi = tf.keras.layers.Conv2D(1, (1, 1), padding='same', name='psi'+name)(act_xg)
    sigmoid_xg = tf.keras.layers.Activation('sigmoid')(psi)

    shape_sigmoid = K.int_shape(sigmoid_xg)
    upsample_psi = tf.keras.layers.UpSampling2D(
                                         size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)


    upsample_psi = expend_as(upsample_psi, shape_x[3],  name)

    y = tf.keras.layers.multiply([upsample_psi, x], name='q_attn'+name)

    result = tf.keras.layers.Conv2D(
                                   shape_x[3], 
                                   (1, 1),
                                    padding='same',
                                    name='q_attn_conv'+name)(y)
    result_bn = tf.keras.layers.BatchNormalization(name='q_attn_bn'+name)(result)
    return result_bn

# %% ../nbs/07_tf_model_creation.ipynb 34
def decoder_block_attention_gates(
    filter_list:List[int],
    encoder_outputs:List[tf.Tensor],
    bottleneck:tf.Tensor,
   ):
    'Create a decoder block for unet with attention gates'

    filter_list = filter_list[::-1]
    encoder_outputs = encoder_outputs[::-1]


    decoder_output_list = []
    x = bottleneck


    for i, filter_no in enumerate(filter_list):

        encoder_output = encoder_outputs[i]

        gating_signal_output = unet_gating_signal(
            x, 
            filter_no,
            is_batchnorm=True, 
            name='gating_signal'+str(i))


        attention_blocks_output = attention_blocks(
            encoder_output,  # like conv_16
            gating_signal_output, # like gate16 
            inter_shape=filter_no, 
            name='attention_block'+str(i))

        #upsample
        x = tf.keras.layers.UpSampling2D(size=(2, 2), data_format='channels_last',name=f'upsampling_{i}')(x)

        # adding attention block to upsample image
        x = tf.keras.layers.concatenate([x, attention_blocks_output], axis=-1)
        
        x = double_conv(
            inputs=x, 
            filter_no=filter_no, 
            kernel_size=3, 
            batch_nm=True, 
            dropout=True, 
            drp_rt=0.1,
            kernel_initializer='glorot_normal' #option he_normal
            )
        decoder_output_list.append(x)
    return x, decoder_output_list


    



# %% ../nbs/07_tf_model_creation.ipynb 38
def unet_model_attention_gates(
    input_size:Tuple[int]=(256, 256, 1),
    filter_list:List[int]=[64,128,256,512],
    kernel_initializer:str='glorot_normal', #option he_normal
    n_classes:int=1
    ):
    'Create a unet model'
    inputs,enc_outputs, final_l = encoder_block(
        input_size=input_size,
        filter_size=filter_list,
        kernel_initializer=kernel_initializer
        )
    final_output, decoder_outputs = decoder_block_attention_gates(
        filter_list=filter_list,
        encoder_outputs=enc_outputs,
        bottleneck=final_l
        )
    if n_classes <=1:   
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='sigmoid')(final_output)
    else:   
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='softmax')(final_output)
    return tf.keras.models.Model(inputs=inputs, outputs=final_output)

# %% ../nbs/07_tf_model_creation.ipynb 43
def res_double_conv(
        inputs, 
        filter_no, 
        kernel_size, 
        batch_nm=True, 
        dropout=True, 
        drp_rt=0.1,
        kernel_initializer='glorot_normal' #option he_normal
        ):
    'Create double conv block with batch norma and dropout'

    # first conv block(conv->bn->relu->dropout)
    c1 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='glorot_normal',
        padding='same',
        activation=None)(inputs)
    if batch_nm:
        c1 = tf.keras.layers.BatchNormalization()(c1)
    c1 = tf.keras.layers.Activation('relu')(c1)
    if dropout:
        c1 = tf.keras.layers.Dropout(drp_rt)(c1)

    # second conv block(conv->bn->relu->dropout)
    c2 = tf.keras.layers.Conv2D(
        filter_no,
        (kernel_size, kernel_size),

        kernel_initializer='glorot_normal',
        padding='same',
        activation=None)(c1)
    if batch_nm:
        c2 = tf.keras.layers.BatchNormalization()(c2)

    if dropout:
        c2 = tf.keras.layers.Dropout(drp_rt)(c2)

    shortcut = tf.keras.layers.Conv2D(
        filter_no,
        (1, 1),
        kernel_initializer=kernel_initializer,
        padding='same',
        activation=None
        )(inputs)

    if batch_nm:
        shortcut = tf.keras.layers.BatchNormalization()(shortcut)
    res_path = tf.keras.layers.add([shortcut, c2])
    res_path = tf.keras.layers.Activation('relu')(res_path)
    return res_path

# %% ../nbs/07_tf_model_creation.ipynb 44
def residual_encoder_block(
        input_size:tf.Tensor,
        filter_size:List[int]=[16,32,64,128,256],
        kernel_initializer:str='glorot_normal' #option he_normal
                 ):
    'Create Encoder block for residual Unet'

    inputs = tf.keras.layers.Input(input_size)
    outputs = []
    p = inputs 
    

    for i in filter_size:
        c = res_double_conv(
            inputs=p, 
            filter_no=i, 
            kernel_size=3, 
            batch_nm=True, 
            dropout=True, 
            drp_rt=0.1,
            kernel_initializer='glorot_normal' #option he_normal
            )
        p = pooling(c, both=True)
        outputs.append(c)

    final_filter_size = filter_size[-1]*2
    final_layer = res_double_conv(
        inputs=p, 
        filter_no=final_filter_size, 
        kernel_size=3, 
        batch_nm=True, 
        dropout=True, 
        drp_rt=0.1,
        kernel_initializer='glorot_normal' #option he_normal
        )
    #outputs.append(final_layer)
    return inputs, outputs, final_layer

# %% ../nbs/07_tf_model_creation.ipynb 45
def residual_decoder_block(
    filter_list:List[int],
    encoder_outputs:List[tf.Tensor],
    bottleneck:tf.Tensor,
   ):
    'Create a decoder block for unet with attention gates'

    filter_list = filter_list[::-1]
    encoder_outputs = encoder_outputs[::-1]


    decoder_output_list = []
    x = bottleneck


    for i, filter_no in enumerate(filter_list):

        encoder_output = encoder_outputs[i]

        gating_signal_output = unet_gating_signal(
            x, 
            filter_no,
            is_batchnorm=True, 
            name='gating_signal'+str(i))


        attention_blocks_output = attention_blocks(
            encoder_output,  # like conv_16
            gating_signal_output, # like gate16 
            inter_shape=filter_no, 
            name='attention_block'+str(i))

        #upsample
        x = tf.keras.layers.UpSampling2D(size=(2, 2), data_format='channels_last',name=f'upsampling_{i}')(x)

        # adding attention block to upsample image
        x = tf.keras.layers.concatenate([x, attention_blocks_output], axis=-1)
        
        x = res_double_conv(
            inputs=x, 
            filter_no=filter_no, 
            kernel_size=3, 
            batch_nm=True, 
            dropout=True, 
            drp_rt=0.1,
            kernel_initializer='glorot_normal' #option he_normal
            )
        decoder_output_list.append(x)
    return x, decoder_output_list


    



# %% ../nbs/07_tf_model_creation.ipynb 46
def residual_attn_unet(
    input_size:Tuple[int]=(256, 256, 1),
    filter_list:List[int]=[64,128,256,512],
    kernel_initializer:str='glorot_normal', #option he_normal
    n_classes:int=1
    ):
    ' Create a residual attention unet model'
    inputs, enc_outputs, bottleneck = residual_encoder_block(
        input_size=input_size,
        filter_size=filter_list,
        kernel_initializer=kernel_initializer
        )
    final_output, decoder_outputs = residual_decoder_block(
        filter_list=filter_list,
        encoder_outputs=enc_outputs,
        bottleneck=bottleneck
        )
    if n_classes <=1:   
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='sigmoid')(final_output)
    else:
        final_output = tf.keras.layers.Conv2D(
            n_classes,(1, 1), activation='softmax')(final_output)

    return tf.keras.models.Model(inputs=inputs, outputs=final_output)


