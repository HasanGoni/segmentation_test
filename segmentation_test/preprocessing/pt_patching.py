"""Patch whole image into number of patches"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/110_preprocessing.pt_patching.ipynb.

# %% auto 0
__all__ = ['ImageToPatchLayer', 'PatchToImageLayer', 'RobustPatchProcessingNetwork', 'OptimizedImageToPatchLayer',
           'SizePreservingPatchLayer', 'ExactSizePatchNetwork', 'SizePreservingPatchMerger']

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 2
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 4
class ImageToPatchLayer(nn.Module):
    """Custom layer to convert images into patches.
    Maintains ONNX compatibility by using standard torch operations."""
    
    def __init__(self, patch_size=256, stride=None, padding_mode='reflect'):
        super().__init__()
        self.patch_size = patch_size
        self.stride = stride if stride is not None else patch_size
        self.padding_mode = padding_mode
        
    def forward(self, x):
        """
        Args:
            x: Input tensor of shape (B, C, H, W)
        Returns:
            Patches tensor of shape (B, N, C, patch_size, patch_size)
            where N is the number of patches
        """
        B, C, H, W = x.shape
        
        # Calculate padding
        pad_h = (self.patch_size - H % self.patch_size) % self.patch_size
        pad_w = (self.patch_size - W % self.patch_size) % self.patch_size
        
        # Apply padding if needed
        if pad_h > 0 or pad_w > 0:
            x = F.pad(x, (0, pad_w, 0, pad_h), mode=self.padding_mode)
        
        # Unfold into patches using standard torch operations
        patches = F.unfold(x, 
                          kernel_size=(self.patch_size, self.patch_size),
                          stride=self.stride)
        
        # Reshape to (B, N, C, patch_size, patch_size)
        patches = patches.view(B, C, self.patch_size, self.patch_size, -1)
        patches = patches.permute(0, 4, 1, 2, 3)
        
        return patches

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 5
class PatchToImageLayer(nn.Module):
    """Custom layer to reconstruct image from patches.
    Maintains ONNX compatibility by using standard torch operations."""
    
    def __init__(self, output_size=None, patch_size=256, stride=None):
        super().__init__()
        self.output_size = output_size
        self.patch_size = patch_size
        self.stride = stride if stride is not None else patch_size
        
    def forward(self, x, original_size=None):
        """
        Args:
            x: Input tensor of patches (B, N, C, patch_size, patch_size)
            original_size: Optional tuple of (H, W) for output size
        Returns:
            Reconstructed image tensor of shape (B, C, H, W)
        """
        B, N, C, H, W = x.shape
        
        # Reshape patches for fold operation
        x = x.permute(0, 2, 3, 4, 1)
        x = x.reshape(B, C * H * W, N)
        
        # Calculate output size
        if original_size is not None:
            output_h, output_w = original_size
        elif self.output_size is not None:
            output_h, output_w = self.output_size
        else:
            # Calculate based on number of patches and stride
            output_h = int(math.sqrt(N)) * self.stride
            output_w = output_h
        
        # Use fold operation to reconstruct image
        output = F.fold(x,
                       output_size=(output_h, output_w),
                       kernel_size=(self.patch_size, self.patch_size),
                       stride=self.stride)
        
        return output

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 13
class RobustPatchProcessingNetwork(nn.Module):
    """Complete network with robust patch processing."""
    def __init__(self, base_model, patch_size=256, stride=None):
        super().__init__()
        self.patch_maker = RobustImageToPatchLayer(patch_size, stride)
        self.base_model = base_model
        self.patch_merger = RobustPatchToImageLayer(patch_size, stride)
    
    def forward(self, x):
        # Convert to patches
        patches, padding_info = self.patch_maker(x)
        
        # Process patches
        B, N = patches.shape[:2]
        patches = patches.reshape(B * N, *patches.shape[2:])
        processed_patches = self.base_model(patches)
        processed_patches = processed_patches.reshape(B, N, *processed_patches.shape[1:])
        
        # Reconstruct image
        output = self.patch_merger(processed_patches, padding_info)
        
        return output

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 14
class RobustPatchProcessingNetwork(nn.Module):
    """Complete network with robust patch processing."""
    def __init__(self, base_model, patch_size=256, stride=None):
        super().__init__()
        self.patch_maker = RobustImageToPatchLayer(patch_size, stride)
        self.base_model = base_model
        self.patch_merger = RobustPatchToImageLayer(patch_size, stride)
    
    def forward(self, x):
        # Convert to patches
        patches, padding_info = self.patch_maker(x)
        
        # Process patches
        B, N = patches.shape[:2]
        patches = patches.reshape(B * N, *patches.shape[2:])
        processed_patches = self.base_model(patches)
        processed_patches = processed_patches.reshape(B, N, *processed_patches.shape[1:])
        
        # Reconstruct image
        output = self.patch_merger(processed_patches, padding_info)
        
        return output

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 15
class OptimizedImageToPatchLayer(nn.Module):
    """
    Optimized patch conversion for 1152x1632 images with edge effect handling
    """
    def __init__(self, patch_size=256, overlap=32, input_size=(1152, 1632)):
        super().__init__()
        self.patch_size = patch_size
        self.overlap = overlap
        self.input_size = input_size
        
        # Pre-compute optimal grid for given input size
        self.stride = patch_size - overlap
        self.grid_h = (input_size[0] - overlap) // (patch_size - overlap)
        self.grid_w = (input_size[1] - overlap) // (patch_size - overlap)
        
        # Calculate exact padding needed
        self.total_h = (self.grid_h - 1) * (patch_size - overlap) + patch_size
        self.total_w = (self.grid_w - 1) * (patch_size - overlap) + patch_size
        
        self.pad_h = max(0, self.total_h - input_size[0])
        self.pad_w = max(0, self.total_w - input_size[1])
        
        # Create gaussian weight mask for edge effect reduction
        self.register_buffer('weight_mask', self._create_weight_mask())
        

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 26
class SizePreservingPatchLayer(nn.Module):
    """
    Patch conversion layer that guarantees exact input size preservation
    """
    def __init__(self, patch_size=256, min_overlap=32):
        super().__init__()
        self.patch_size = patch_size
        self.min_overlap = min_overlap
        self.register_buffer('weight_mask', self._create_weight_mask())
        
    def _create_weight_mask(self):
        """Creates gaussian weight mask for edge effect reduction"""
        x = torch.linspace(-1, 1, self.patch_size)
        y = torch.linspace(-1, 1, self.patch_size)
        xx, yy = torch.meshgrid(x, y, indexing='ij')
        gaussian = torch.exp(-(xx**2 + yy**2) / 1.5)
        return gaussian

    def _calculate_grid(self, H, W):
        """
        Calculate grid configuration ensuring full coverage of input size
        """
        # Calculate number of patches needed
        n_patches_h = math.ceil(H / (self.patch_size - self.min_overlap))
        n_patches_w = math.ceil(W / (self.patch_size - self.min_overlap))
        
        # Calculate actual strides to exactly cover the image
        stride_h = (H - self.patch_size) / (n_patches_h - 1) if n_patches_h > 1 else 0
        stride_w = (W - self.patch_size) / (n_patches_w - 1) if n_patches_w > 1 else 0
        
        return {
            'n_patches_h': n_patches_h,
            'n_patches_w': n_patches_w,
            'stride_h': stride_h,
            'stride_w': stride_w
        }
    def visualize_patch_grid(self, image_tensor):
        """Visualizes patch grid overlay on image"""
        image = image_tensor[0].cpu().numpy().transpose(1, 2, 0)
        if image.shape[2] == 1:
            image = image.squeeze(-1)
            
        H, W = image.shape[:2]
        grid = self._calculate_grid(H, W)
        
        plt.figure(figsize=(15, 10))
        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)
        
        # Draw actual patch locations
        for i in range(grid['n_patches_h']):
            y = i * grid['stride_h']
            plt.axhline(y=y, color='r', linestyle='--', alpha=0.5)
            if i * grid['stride_h'] + self.patch_size <= H:
                plt.axhline(y=y + self.patch_size, color='g', linestyle=':', alpha=0.3)
                
        for j in range(grid['n_patches_w']):
            x = j * grid['stride_w']
            plt.axvline(x=x, color='r', linestyle='--', alpha=0.5)
            if j * grid['stride_w'] + self.patch_size <= W:
                plt.axvline(x=x + self.patch_size, color='g', linestyle=':', alpha=0.3)
                
        plt.title(f'Patch Grid ({grid["n_patches_h"]}x{grid["n_patches_w"]} patches)\n'
                 f'Image Size: {H}x{W}, Patch Size: {self.patch_size}')
        plt.show()
	
    def forward(self, x):
        B, C, H, W = x.shape
        grid = self._calculate_grid(H, W)
        
        patches = []
        locations = []
        
        # Extract patches with exact positioning
        for i in range(grid['n_patches_h']):
            for j in range(grid['n_patches_w']):
                # Calculate exact patch location
                h_start = int(i * grid['stride_h'])
                w_start = int(j * grid['stride_w'])
                
                # Handle edge cases for last patches
                h_start = min(h_start, H - self.patch_size)
                w_start = min(w_start, W - self.patch_size)
                
                patch = x[:, :,
                         h_start:h_start + self.patch_size,
                         w_start:w_start + self.patch_size]
                
                patches.append(patch)
                locations.append((h_start, w_start))
                
        patches = torch.stack(patches, dim=1)
        
        # Apply weight mask for edge effect reduction
        patches = patches * self.weight_mask.view(1, 1, 1, self.patch_size, self.patch_size)
        
        return patches, (locations, (H, W))

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 27
class ExactSizePatchNetwork(nn.Module):
    """
    Network that guarantees exact size preservation
    """
    def __init__(self, base_model, patch_size=256, min_overlap=32):
        super().__init__()
        self.patch_maker = SizePreservingPatchLayer(patch_size, min_overlap)
        self.base_model = base_model
        self.patch_merger = SizePreservingPatchMerger(patch_size)
        
    def visualize_patches(self, x):
        self.patch_maker.visualize_patch_grid(x)
        
    def forward(self, x):
        # Store original size for verification
        original_size = x.shape
        
        # Convert to patches
        patches, info = self.patch_maker(x)
        
        # Process patches
        B, N = patches.shape[:2]
        patches = patches.reshape(B * N, *patches.shape[2:])
        processed_patches = self.base_model(patches)
        processed_patches = processed_patches.reshape(B, N, *processed_patches.shape[1:])
        
        # Reconstruct image
        output = self.patch_merger(processed_patches, info)
        
        # Verify size match
        assert output.shape == original_size, \
            f"Size mismatch: Input {original_size}, Output {output.shape}"
            
        return output

# %% ../../nbs/110_preprocessing.pt_patching.ipynb 28
class SizePreservingPatchMerger(nn.Module):
    """
    Patch merging layer that guarantees exact size preservation
    """
    def __init__(self, patch_size=256):
        super().__init__()
        self.patch_size = patch_size
        
    def forward(self, patches, info):
        locations, (H, W) = info
        B, N, C, H_patch, W_patch = patches.shape
        
        # Initialize output and weight accumulator with exact input size
        output = torch.zeros((B, C, H, W), device=patches.device)
        weights = torch.zeros((B, 1, H, W), device=patches.device)
        
        # Reconstruct image using exact patch locations
        for idx, (h_start, w_start) in enumerate(locations):
            patch = patches[:, idx]
            h_end = min(h_start + self.patch_size, H)
            w_end = min(w_start + self.patch_size, W)
            
            output[:, :, h_start:h_end, w_start:w_end] += patch[:, :, :(h_end-h_start), :(w_end-w_start)]
            weights[:, :, h_start:h_end, w_start:w_end] += 1
            
        # Average overlapping regions
        output = output / (weights + 1e-8)
        return output
