# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_pytorch_ds_creation.ipynb.

# %% auto 0
__all__ = ['show_hf_dataset', 'SegmentationDataset', 'UNetSmall', 'TverskyFocalLoss', 'train']

# %% ../nbs/05_pytorch_ds_creation.ipynb 3
from datasets import load_dataset, Dataset as HFDataset
from torch.utils.data import Dataset
from typing import List, Dict, Union, Optional, Tuple
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import pandas as pd
from pathlib import Path
from tqdm.auto import tqdm
import matplotlib as mpl 
import albumentations as A

# %% ../nbs/05_pytorch_ds_creation.ipynb 4
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import CosineAnnealingLR

# %% ../nbs/05_pytorch_ds_creation.ipynb 9
def show_hf_dataset(
        dataset:HFDataset,
        idx:Union[int, None]=None,
        split:str='train'
        ):
    "Show hugging face random index"

    if idx is None:
        idx = np.random.randint(0, len(dataset[split]))

    print(f' dataset index will be visualized: {idx}')
    im_ = dataset[split]['image'][idx]
    msk_ = dataset[split]['label'][idx]
    fig, ax = plt.subplots(
        1, 2, figsize=(10, 5)
    )
    ax[0].imshow(im_)
    ax[0].set_title('image')
    ax[0].axis('off')
    ax[1].imshow(msk_)
    ax[1].set_title('mask')
    ax[1].axis('off')
    

# %% ../nbs/05_pytorch_ds_creation.ipynb 14
class SegmentationDataset(Dataset):
  def __init__(
              self, 
              dataset, 
              transform # Transformations
              ):
    self.dataset = dataset
    self.transform = transform

  def __len__(self):
    return len(self.dataset)

  def __getitem__(self, idx):
    item = self.dataset[idx]
    original_image = np.expand_dims(np.array(item["image"]),axis=-1)
    original_segmentation_map = np.expand_dims(np.array(item["label"]),-1)

    transformed = self.transform(image=original_image, mask=original_segmentation_map)
    image, target = torch.tensor(transformed['image']), torch.LongTensor(transformed['mask'])
    #print(image.shape)

    #########################################################################################
    # convert to C, H, W
    image = image.permute(2,0,1)
    target = target.permute(2,0,1)
    #########################################################################################

    return image, target, original_image, original_segmentation_map

# %% ../nbs/05_pytorch_ds_creation.ipynb 31
class UNetSmall(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UNetSmall, self).__init__()
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        # Middle
        self.middle = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.Conv2d(96, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, out_channels, kernel_size=1)
        )
        
    def forward(self, x):
        # Encoder
        x1 = self.encoder(x)
        
        # Middle
        x2 = self.middle(x1)
        
        # Decoder
        x3 = torch.cat([x1, x2], dim=1)
        x4 = self.decoder(x3)
        
        return x4


# %% ../nbs/05_pytorch_ds_creation.ipynb 32
class TverskyFocalLoss(nn.Module):
    def __init__(self, alpha=0.7, beta=0.3, gamma=2.0, epsilon=1e-5):
        super(TverskyFocalLoss, self).__init__()
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.epsilon = epsilon

    def forward(self, y_true, y_pred):
        y_true = y_true.view(-1)
        y_pred = y_pred.view(-1)

        true_positive = (y_true * y_pred).sum()
        false_positive = ((1 - y_true) * y_pred).sum()
        false_negative = (y_true * (1 - y_pred)).sum()

        tversky = (true_positive + self.epsilon) / (true_positive + self.alpha * false_positive + self.beta * false_negative + self.epsilon)

        focal_tversky = (1 - tversky)**self.gamma

        return focal_tversky.mean()


# %% ../nbs/05_pytorch_ds_creation.ipynb 36
def train(
        train_dataloader:DataLoader,
        val_dataloader:DataLoader,
        optimizer:torch.optim.Optimizer,
        model:torch.nn.Module,
        criterion:torch.nn.Module,
        device:torch.device,
        epochs:int,
        save_path:str
):
    num_epochs = epochs
    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00001)

    for epoch in range(num_epochs):
        print(f'epoch: {epoch+1}/{num_epochs}')

        model.train()

        for idx, batch in enumerate(tqdm(train_dataloader)):
            images = batch['pixel_values'].to(device)
            masks = batch['labels'].to(device)
            optimizer.zero_grad()

            outputs = model(images)
            loss = criterion(outputs, masks)

            loss.backward()
            optimizer.step()
        scheduler.step()  # Update learning rate
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.8f}')

         # Validation loop
        model.eval()
        with torch.no_grad():
            total_val_loss = 0
            for idx, val_batch in enumerate(tqdm(val_dataloader)):
                val_images = val_batch['pixel_values'].to(device)
                val_masks = val_batch['labels'].to(device)
                val_outputs = model(val_images)
                val_loss = criterion(val_outputs, val_masks)
                total_val_loss += val_loss.item()

        avg_val_loss = total_val_loss / len(val_dataloader)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {avg_val_loss:.4f}')

    save_model(model, save_path)


