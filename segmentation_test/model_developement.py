# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_model_developement.ipynb.

# %% auto 0
__all__ = ['block_shortcut', 'blocks', 'VGG_16', 'fcn_8_decoder', 'segmentation_model', 'CosineDecay']

# %% ../nbs/02_model_developement.ipynb 3
import os
#os.environ['CUDA_VISIBLE_DEVICES'] = ''
import tensorflow as tf
import datetime
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from pathlib import Path
from functools import partial
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from fastcore.basics import patch
from fastcore.all import *
from tensorflow.keras.models import Model
from IPython.display import display, clear_output
#from fastai.vision.all import *
from dataclasses import dataclass, field
from .preprocessing import *
from .config import *
#from segmentation_test.viz_utils import *
#from segmentation_test.viz_utils import *


from typing import Union, List, Tuple, Optional, Callable, Dict, Any

# %% ../nbs/02_model_developement.ipynb 9
def blocks(
    x:tf.Tensor, 
    n_convs:int,
    filters:int,
    kernel_size:int=3,
    activation:str='relu',
    pool_size:int=2,
    pool_stride:int=2,
    name:str='block'):
    for i in range(n_convs):
        x = tf.keras.layers.Conv2D(
            filters=filters, 
            kernel_size=kernel_size, 
            padding='same',
            activation=activation, 
            name=f'{name}_conv{i}')(x)
    x = tf.keras.layers.MaxPool2D(
                                 pool_size=pool_size,
                                 strides=pool_stride,
                                 name=f'{name}_pool{i}'
                                 )(x)
    return x


# %% ../nbs/02_model_developement.ipynb 10
block_shortcut = partial(
                       blocks, kernel_size=(3,3),
                       pool_size=(2,2),
                       pool_stride=(2,2),
                       activation='relu')

# %% ../nbs/02_model_developement.ipynb 11
def VGG_16(
        input_image:tf.Tensor):

    x = block_shortcut(
            input_image, n_convs=2,
            filters=64,
            name='block1')
    p1 = x
    x = block_shortcut(
           x, n_convs=2,
           filters=128,
           name='block2')
    p2 = x
    x = block_shortcut(
            x, n_convs=3,
            filters=256,
            name='block3')
    p3 = x
    x = block_shortcut(
           x, n_convs=3,
           filters=512,
           name='block4')
    p4 = x
    x = block_shortcut(
           x, n_convs=3,
           filters=512,
           name='block5')
    p5 = x

    # creating model
    vgg = tf.keras.Model(
            inputs=input_image,
            outputs=p5)

    # This vgg is our encoder, now
    # we will process outer layer so that
    # decoder can work on it
    # number of filters for the output convolutional layers
    n = 4096

    # our input images are 224x224 pixels so they will be
    # downsampled to 7x7 after the pooling layers above.
    # we can extract more features by chaining two more
    # convolution layers.
    c6 = tf.keras.layers.Conv2D(
           n, (7, 7), padding='same',
           activation='relu',
           name='conv6')(p5)
    c7 = tf.keras.layers.Conv2D(
           n, (1, 1), padding='same',
           activation='relu',
           name='conv7')(c6)
    return (p1, p2, p3, p4, c7)

# %% ../nbs/02_model_developement.ipynb 15
def fcn_8_decoder(convs, n_classes):
    """
    Defines the FCN 8 decoder.
    Args:
    convs (tuple of tensors) - output of the encoder network
    n_classes (int) - number of classes
    Returns:
    tensor with shape (height, width, n_classes) containing class probabilities
    """
    # unpack the output of the encoder
    f1, f2, f3, f4, f5 = convs
    # upsample the output of the encoder then crop extra pixels # that were introduced
    o1 = tf.keras.layers.Conv2DTranspose(
               n_classes, kernel_size=(4, 4),
               strides=(2, 2),
               use_bias=False)(f5)
    o1 = tf.keras.layers.Cropping2D(
               cropping=(1, 1))(o1)
    # load the pool 4 prediction and do a
    # 1x1 convolution to reshape it to the same shape of `o1` above
    o2 = f4
    o2 = tf.keras.layers.Conv2D(
               n_classes,
               (1, 1),
               activation='relu',
               padding='same')(f4)
    # add the results of the upsampling and pool 4 prediction
    o1 = tf.keras.layers.Add()([o1, o2])

    # Now upsampling the resulting tensor 2 times
    o1 = tf.keras.layers.Conv2DTranspose(
              n_classes, (4, 4),
              strides=(2, 2),
              use_bias=False)(f3)
    o1 = tf.keras.layers.Cropping2D(
             cropping=(1, 1))(o1)

    # load the pool 3 prediction and do a 1x1 convolution to reshape it to the
    # same shape of `o1` above
    o2 = f2
    o2 = tf.keras.layers.Conv2D(
             n_classes, (1, 1),
             padding='same',
             activation='relu'
             )(f2)
    # add the results of the upsampling and pool 3 prediction
    o1 = tf.keras.layers.Add()([o1, o2])
    

    # upsample up to the size of the original image
    o1 = tf.keras.layers.Conv2DTranspose(
            num_classes,
            (8, 8),
            strides=(8, 8),
            use_bias=False)(f1)
    o1 = tf.keras.layers.Conv2D(
             n_classes, (1, 1),
             padding='same',
             activation='relu'
             )(o1)
    # append a softmax to get the class probabilities
    o1 = tf.keras.layers.Activation(
          'softmax')(o1)

    return o1

# %% ../nbs/02_model_developement.ipynb 16
def segmentation_model():
    """
    Model will be created from encoder and decoder
    """
    inputs = tf.keras.layers.Input(
           shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1,))
    convs = VGG_16(
            input_image=inputs
            )
    outputs = fcn_8_decoder(
             convs,
             num_classes)
    model = tf.keras.Model(
            inputs=inputs,
            outputs=outputs)
    return model

# %% ../nbs/02_model_developement.ipynb 22
class CosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, initial_learning_rate, total_steps, warmup_steps=0, alpha=0.0, name=None):
        super().__init__()
        self.initial_learning_rate = tf.cast(initial_learning_rate, tf.float64)
        self.total_steps = total_steps
        self.warmup_steps = warmup_steps
        self.alpha = alpha
        self.name = name
        
    def __call__(self, step):
        if self.warmup_steps > 0:
            lr = (step / self.warmup_steps) * self.initial_learning_rate
        else:
            lr = self.initial_learning_rate
            
        cosine_decay = 0.5 * (1 + tf.math.cos(tf.constant(math.pi) * (tf.cast(step, dtype=tf.float32) - self.warmup_steps) / float(self.total_steps - self.warmup_steps)))
        decayed = (1 - self.alpha) * cosine_decay + self.alpha
        decayed = tf.cast(decayed, tf.float64)
        return lr * decayed
    
    def get_config(self):
        return {
            "initial_learning_rate": self.initial_learning_rate,
            "total_steps": self.total_steps,
            "warmup_steps": self.warmup_steps,
            "alpha": self.alpha,
            "name": self.name
        }
    

