# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/09_dataset_creation.ipynb.

# %% auto 0
__all__ = ['get_transforms', 'SegmentationDataset', 'repeat_collate_fn', 'split_ds', 'InferenceDataset',
           'create_pytorch_dataloader', 'get_training_augmentation', 'get_validation_augmentation', 'visualize_batch']

# %% ../nbs/09_dataset_creation.ipynb 4
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.utils.data import Dataset, DataLoader, random_split, Subset
from PIL import Image
from typing import List, Callable, Tuple, Dict, Union
from pathlib import Path
from fastcore.all import *
import cv2
import torch
from fastcore.all import *
from fastcore.foundation import *


import matplotlib.pyplot as plt
import numpy as np

# %% ../nbs/09_dataset_creation.ipynb 5
def get_transforms(*, data):
    if data == 'train':
        return A.Compose([
            #A.Resize(256, 256),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.RandomRotate90(p=0.5),
            A.Transpose(p=0.5),
            A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),
            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),
            ToTensorV2(),
        ])

    elif data == 'valid':
        return A.Compose([
            #A.Resize(256, 256),
            A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),
            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

# %% ../nbs/09_dataset_creation.ipynb 8
class SegmentationDataset(Dataset):
    def __init__(self, image_path, mask_path, exts, transform=None):
        self.image_path = image_path
        self.mask_path = mask_path
        self.exts = exts
        self.images = Path(image_path).ls(file_exts=exts)
        self.masks = Path(mask_path).ls(file_exts=exts)
        self.transform = transform

        super().__init__()
        store_attr()
        __repr__ = basic_repr()

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        name_ = Path(img_path).name
        msk_path = Path(self.mask_path, name_)
        image = np.array(Image.open(img_path).convert('L'), dtype=np.float32) / 255.0 # convert to grayscale
        mask = np.array(Image.open(msk_path).convert('L'), dtype=np.float32) / 255.0


        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']
        mask = np.where(mask > 0.5, 1.0, 0.0)
        mask = mask[None, ...]

        return image, mask# Add channel dimension to mask

# %% ../nbs/09_dataset_creation.ipynb 15
def repeat_collate_fn(batch, batch_size=4):
    images, masks = zip(*batch)

    images = list(images)
    masks = list(masks)

    num_to_add = batch_size - len(images)
    if num_to_add > 0:
        for i in range(num_to_add):
            index = i%len(images)
            images.append(images[index])
            masks.append(masks[index])
    return torch.stack(images), torch.stack(masks)


# %% ../nbs/09_dataset_creation.ipynb 16
def split_ds(ds:Dataset, val_split:float=0.2):
    val_len = int(len(ds) * val_split)
    trn_ds = Subset(ds, indices=range(val_len))
    val_ds = Subset(ds, indices=range(val_len, len(ds)))
    return trn_ds, val_ds


# %% ../nbs/09_dataset_creation.ipynb 18
class InferenceDataset(Dataset):
    def __init__(self, image_dir,transform=None):
        self.image_dir = image_dir
        self.images = Path(image_dir).ls()
        self.image_names = get_name_(self.images)
        self.transform = transform

        super().__init__()
        store_attr()
        __repr__ = basic_repr()

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = np.array(Image.open(img_path).convert('L'), dtype=np.float32) / 255.0 # convert to grayscale
        if len(image.shape) == 2:
            image = image[:, :, None]

        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']

        return image, self.image_names[idx]



# %% ../nbs/09_dataset_creation.ipynb 19
def create_pytorch_dataloader(
    split_type:str, # in case of 'random' randomly data will be splitted
    split_per:float, # percentage of training data
    batch_size:int,
    image_path:Union[Path, str],
    mask_path:Union[Path, str],
    trn_transforms:Callable, # a callable function trn_transforms 
    val_transforms:Callable, # a callable function val_transforms
    exts:str='.png',  # image  and mask data extensions
	val_im_path:Union[Path, str]=None,
	val_msk_path:Union[Path, str]=None,
	tst_im_path:Union[Path, str]=None,
    collate_fn:Callable=repeat_collate_fn,
    num_workers:str=4
   ):

    'Create pytorch dataloader based on the argument'
    if split_type == 'random':

        full_dataset = SegmentationDataset(
                                image_path=image_path,
                                mask_path=mask_path,
                                exts=exts
                              )
        trn_ds, val_ds = split_ds(full_dataset, val_split=split_per)
        trn_ds.dataset.transform = trn_transforms
        val_ds.dataset.transform = val_transforms

    else:
        trn_ds = SegmentationDataset(image_path=im_path, mask_path=mask_path, exts=exts)
        val_ds = SegmentationDataset(image_path=val_im_path, mask_path=val_msk_path, exts=exts)

    print(f' training dataset length = {len(trn_ds)} and validation dataset length=  {len(val_ds)}')
        

    if num_workers > 0:

        train_dl = DataLoader(
                            trn_ds, 
                            batch_size=batch_size,
                            shuffle=True, 
                            num_workers=num_workers, 
                            pin_memory=True,
                            collate_fn=collate_fn,
                            persistent_workers=True, 
							prefetch_factor=2,
        )
        val_dl = DataLoader(
                            val_ds, 
                            batch_size=batch_size,
                            shuffle=False, 
                            num_workers=num_workers, 
                            pin_memory=True,
                            collate_fn=collate_fn,
							prefetch_factor=2,
        )
    else:
        train_dl = DataLoader(
                            trn_ds, 
                            batch_size=batch_size,
                            shuffle=True, 
                            num_workers=num_workers, 
                            pin_memory=True,
                            collate_fn=collate_fn)
        val_dl = DataLoader(
                            val_ds, 
                            batch_size=batch_size,
                            shuffle=False, 
                            num_workers=num_workers, 
                            pin_memory=True,
                            collate_fn=collate_fn)
    if tst_im_path:
        tst_ds = InferenceDataset(image_dir=tst_im_path, transform=val_transforms)
        if num_workers > 0:
            tst_dl = DataLoader(tst_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, collate_fn=collate_fn, persistent_workers=True, prefetch_factor=2)
        else:
            tst_dl = DataLoader(tst_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, collate_fn=collate_fn)
        return train_dl, val_dl, tst_dl
    return train_dl, val_dl

    




# %% ../nbs/09_dataset_creation.ipynb 22
def get_training_augmentation(
    IMAGE_HEIGHT: int = 592,
    IMAGE_WIDTH: int = 592,

):
    train_transform = [
         A.RandomCrop(height=592, width=592),
        A.Perspective(p=0.3),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.Rotate(limit=35, p=0.5),
        A.GaussNoise(var_limit=(.02, .005), p=0.3),  # Add Gaussian noise
        A.ElasticTransform(p=0.1, alpha=3, sigma=50 * 0.05),
        A.GridDistortion(p=0.1),
        A.OpticalDistortion(p=0.1, distort_limit=1, shift_limit=0.5),
        ToTensorV2(),
    ]
    return A.Compose(train_transform)



# %% ../nbs/09_dataset_creation.ipynb 23
def get_validation_augmentation(
    IMAGE_HEIGHT: int = 592,
    IMAGE_WIDTH: int = 592,
):
    return A.Compose([A.CenterCrop(height=592, width=592), ToTensorV2()])

# %% ../nbs/09_dataset_creation.ipynb 26
def visualize_batch(images, masks, num_images=4):
    fig, axs = plt.subplots(1,num_images, figsize=(5, num_images*5))
    for idx, (image, mask) in enumerate(zip(images, masks)):
        if idx >= num_images:
            break
        axs[idx].imshow(image.permute(1, 2, 0)[:,:,0], cmap='gray')
        axs[idx].imshow(mask.squeeze(), cmap='jet', alpha=0.3)  # overlay mask on image
        axs[idx].axis('off')
        axs[idx].set_title('Image with Mask')
    plt.tight_layout()
    plt.show()
