{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Segmentation from timm in Pytorch\n",
    "> This is a simple example of training segmentation model using timm in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp xception_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from cv_tools.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XceptionBinarySegmentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XceptionBinarySegmentation, self).__init__()\n",
    "        # Create Xception model from scratch with single-channel input\n",
    "        self.xception = timm.create_model(\n",
    "            'xception', \n",
    "            pretrained=False, \n",
    "            in_chans=1, \n",
    "            features_only=True)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(2048, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        self.upsample = nn.Upsample(size=(1152, 1632), mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.xception(x)\n",
    "        x = self.decoder(features[-1])\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_transforms = A.Compose([\n",
    "            #A.Resize(256, 256),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "            A.Perspective(p=0.25),\n",
    "            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            #A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),\n",
    "            ToTensorV2()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = A.Compose([\n",
    "            #A.Resize(256, 256),\n",
    "            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            #A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),\n",
    "            ToTensorV2()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_test.dataloader_creation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/user/Schreibtisch/projects/git_data/segmentation_test/data/images')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = Path(Path.cwd().parent, 'data/images')\n",
    "mask_path = Path(Path.cwd().parent, 'data/masks')\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of images found = 7901\n",
      " training dataset length = 6320 and validation dataset length=  1581\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = create_pytorch_dataloader(\n",
    "    split_type='random',\n",
    "\tsplit_per=0.8,\n",
    "\texts='.png',\n",
    "\tbatch_size=4,\n",
    "\timage_path=image_path,\n",
    "\tmask_path=mask_path,\n",
    "\ttrn_transforms=trn_transforms,\n",
    "\tval_transforms=val_transforms,\n",
    "\tcollate_fn=repeat_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('12_xception_segmentation.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
