{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Training script in MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pretraining Training script in MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mae.pretraining_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 23:00:42.215491: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-21 23:00:42.604966: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-21 23:00:42.605021: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-21 23:00:42.605040: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-21 23:00:42.871513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Iterable\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.9'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import segmentation_test.mae.misc as misc\n",
    "import segmentation_test.mae.model_development as models_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import math\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Scaling and Norm Counting: \n",
    "\n",
    "\n",
    "Dealing with mixed precision training, where we use both 16-bit and 32-bit floating-point numbers to speed up computation and reduce memory usage. But this can lead to some tricky numerical issues. Enter the `NativeScalerWithGradNormCount` class!\n",
    "\n",
    "## What's this class all about?\n",
    "\n",
    "This nifty little class is a wrapper around PyTorch's `GradScaler`. It's designed to handle the intricacies of mixed precision training while also giving us some extra goodies like gradient norm calculation.\n",
    "\n",
    "## Let's break it down:\n",
    "\n",
    "1. **Initialization**: We start by creating a `GradScaler` object. This is PyTorch's built-in tool for automatic mixed precision training.\n",
    "\n",
    "2. **The `__call__` method**: This is where the magic happens!\n",
    "   - It scales the loss and performs backpropagation.\n",
    "   - If we're updating gradients, it handles gradient unscaling and clipping.\n",
    "   - It also calculates the gradient norm, which is super useful for monitoring training stability.\n",
    "\n",
    "3. **State management**: The `state_dict` and `load_state_dict` methods allow us to save and load the scaler's state. This is crucial for resuming training from checkpoints.\n",
    "\n",
    "## Why is this so cool?\n",
    "\n",
    "- It seamlessly integrates mixed precision training into our workflow.\n",
    "- It provides gradient clipping out of the box, which helps prevent exploding gradients.\n",
    "- The gradient norm calculation gives us valuable insights into our training process.\n",
    "\n",
    "By using this class, we're not just training our model - we're training it smartly and efficiently. It's like having a personal trainer for your neural network!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NativeScalerWithGradNormCount:\n",
    "    state_dict_key = \"amp_scaler\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def __call__(\n",
    "\t\tself, \n",
    "\t\tloss, \n",
    "\t\toptimizer, \n",
    "\t\tclip_grad=None, \n",
    "\t\tparameters=None, \n",
    "\t\tcreate_graph=False, \n",
    "\t\tupdate_grad=True):\n",
    "        self._scaler.scale(loss).backward(create_graph=create_graph)\n",
    "        if update_grad:\n",
    "            if clip_grad is not None:\n",
    "                assert parameters is not None\n",
    "                self._scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n",
    "                norm = torch.nn.utils.clip_grad_norm_(parameters, clip_grad)\n",
    "            else:\n",
    "                self._scaler.unscale_(optimizer)\n",
    "                norm = get_grad_norm_(parameters)\n",
    "            self._scaler.step(optimizer)\n",
    "            self._scaler.update()\n",
    "        else:\n",
    "            norm = None\n",
    "        return norm\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self._scaler.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self._scaler.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def adjust_learning_rate(\n",
    "\toptimizer, \n",
    "\tepoch, \n",
    "\targs\n",
    "\t):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < args.warmup_epochs:\n",
    "        lr = args.lr * epoch / args.warmup_epochs \n",
    "    else:\n",
    "        lr = args.min_lr + (args.lr - args.min_lr) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - args.warmup_epochs) / (args.epochs - args.warmup_epochs)))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if \"lr_scale\" in param_group:\n",
    "            param_group[\"lr\"] = lr * param_group[\"lr_scale\"]\n",
    "        else:\n",
    "            param_group[\"lr\"] = lr\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_adjust_learning_rate():\n",
    "    class DummyOptimizer:\n",
    "        def __init__(self):\n",
    "            self.param_groups = [\n",
    "\t\t\t\t{\"lr\": 0.1}, \n",
    "\t\t\t\t{\"lr\": 0.2, \"lr_scale\": 2}\n",
    "\t\t\t]\n",
    "\n",
    "    class DummyArgs:\n",
    "        def __init__(self):\n",
    "            self.warmup_epochs = 5\n",
    "            self.epochs = 100\n",
    "            self.lr = 0.1\n",
    "            self.min_lr = 0.001\n",
    "\n",
    "    optimizer = DummyOptimizer()\n",
    "    args = DummyArgs()\n",
    "\n",
    "    # Test during warmup\n",
    "    lr = adjust_learning_rate(optimizer, 2, args)\n",
    "    test_eq(lr, 0.04)\n",
    "    test_eq(optimizer.param_groups[0][\"lr\"], 0.04)\n",
    "    test_eq(optimizer.param_groups[1][\"lr\"], 0.08)\n",
    "\n",
    "    # Test after warmup\n",
    "    lr = adjust_learning_rate(optimizer, 50, args)\n",
    "    expected_lr = 0.001 + (0.1 - 0.001) * 0.5 * (1 + math.cos(math.pi * 45 / 95))\n",
    "    test_close(lr, expected_lr, eps=1e-6)\n",
    "    test_close(optimizer.param_groups[0][\"lr\"], expected_lr, eps=1e-6)\n",
    "    test_close(optimizer.param_groups[1][\"lr\"], expected_lr * 2, eps=1e-6)\n",
    "    print(\"All tests passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "test_adjust_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_one_epoch(\n",
    "\t            model: torch.nn.Module,\n",
    "                data_loader: Iterable, \n",
    "\t\t\t\toptimizer: torch.optim.Optimizer,\n",
    "                device: torch.device, \n",
    "\t\t\t\tepoch: int, \n",
    "\t\t\t\tloss_scaler: NativeScalerWithGradNormCount,\n",
    "                log_writer=None,\n",
    "                args=None):\n",
    "    model.train(True)\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 20\n",
    "\n",
    "    accum_iter = args.accum_iter\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if log_writer is not None:\n",
    "        print('log_dir: {}'.format(log_writer.log_dir))\n",
    "\n",
    "    for data_iter_step, (samples, _) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "\n",
    "        # we use a per iteration (instead of per epoch) lr scheduler\n",
    "        if data_iter_step % accum_iter == 0:\n",
    "            lr_sched.adjust_learning_rate(optimizer, data_iter_step / len(data_loader) + epoch, args)\n",
    "\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss, _, _ = model(samples, mask_ratio=args.mask_ratio)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            sys.exit(1)\n",
    "\n",
    "        loss /= accum_iter\n",
    "        loss_scaler(\n",
    "\t\t\tloss, \n",
    "\t\t\toptimizer, \n",
    "\t\t\tparameters=model.parameters(),\n",
    "            update_grad=(data_iter_step + 1) % accum_iter == 0\n",
    "\t\t)\n",
    "        if (data_iter_step + 1) % accum_iter == 0:\n",
    "        \toptimizer.zero_grad()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        metric_logger.update(loss=loss_value)\n",
    "\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        metric_logger.update(lr=lr)\n",
    "\n",
    "        loss_value_reduce = misc.all_reduce_mean(loss_value)\n",
    "        if log_writer is not None and (data_iter_step + 1) % accum_iter == 0:\n",
    "            \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "\t\t\tThis calibrates different curves when batch size changes.\n",
    "\t\t\t\"\"\"\n",
    "            epoch_1000x = int((data_iter_step / len(data_loader) + epoch) * 1000)\n",
    "            log_writer.add_scalar('train_loss', loss_value_reduce, epoch_1000x)\n",
    "            log_writer.add_scalar('lr', lr, epoch_1000x)\n",
    "\n",
    "\n",
    "\t# gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main_pretrain.py script will be implemented here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> engine_pretrain.py needs to be implemented here, and call main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageWang dataset downloaded and extracted to: /home/user/.fastai/data/imagewang-160\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import untar_data, URLs\n",
    "\n",
    "# Download and extract the ImageWang dataset (a subset of ImageNet)\n",
    "path = untar_data(URLs.IMAGEWANG_160)\n",
    "\n",
    "# Update the DATA_PATH to point to the downloaded dataset\n",
    "DATA_PATH = str(path)\n",
    "\n",
    "print(f\"ImageWang dataset downloaded and extracted to: {DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/user/.fastai/data/imagewang-160/val'),Path('/home/user/.fastai/data/imagewang-160/train'),Path('/home/user/.fastai/data/imagewang-160/unsup')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(DATA_PATH).ls()\n",
    "# MAE pre-training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE pre-training arguments\n",
    "BATCH_SIZE = 64  # Batch size per GPU (effective batch size is BATCH_SIZE * ACCUM_ITER * # gpus)\n",
    "EPOCHS = 400\n",
    "ACCUM_ITER = 1  # Accumulate gradient iterations (for increasing the effective batch size under memory constraints)\n",
    "\n",
    "# Model parameters\n",
    "MODEL = 'mae_vit_large_patch16'  # Name of model to train\n",
    "INPUT_SIZE = 224  # images input size\n",
    "MASK_RATIO = 0.75  # Masking ratio (percentage of removed patches)\n",
    "NORM_PIX_LOSS = False  # Use (per-patch) normalized pixels as targets for computing loss\n",
    "\n",
    "# Optimizer parameters\n",
    "WEIGHT_DECAY = 0.05\n",
    "LR = None  # learning rate (absolute lr)\n",
    "BLR = 1e-3  # base learning rate: absolute_lr = base_lr * total_batch_size / 256\n",
    "MIN_LR = 0.  # lower lr bound for cyclic schedulers that hit 0\n",
    "WARMUP_EPOCHS = 40  # epochs to warmup LR\n",
    "\n",
    "# Dataset parameters\n",
    "DATA_PATH = str(path)  # dataset path\n",
    "# Typically, this folder structure contains:\n",
    "# - 'train' folder: Contains subfolders for each class, with training images\n",
    "# - 'val' folder: Contains subfolders for each class, with validation images\n",
    "# - 'test' folder: (optional) Contains test images, if provided\n",
    "# - 'labels.txt' or similar: A file mapping class names to numeric IDs\n",
    "OUTPUT_DIR = './output_dir'  # path where to save, empty for no saving\n",
    "LOG_DIR = './output_dir'  # path where to tensorboard log\n",
    "DEVICE = 'cuda'  # device to use for training / testing\n",
    "SEED = 0\n",
    "RESUME = ''  # resume from checkpoint\n",
    "START_EPOCH = 0\n",
    "NUM_WORKERS = 4# 10 was too much for my GPU\n",
    "PIN_MEM = True  # Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.\n",
    "\n",
    "# distributed training parameters\n",
    "WORLD_SIZE = 1  # number of distributed processes\n",
    "LOCAL_RANK = -1\n",
    "DIST_ON_ITP = False\n",
    "DIST_URL = 'env://'  # url used to set up distributed training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleNamespace object to mimic argparse.Namespace\n",
    "args = SimpleNamespace(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    accum_iter=ACCUM_ITER,\n",
    "    model=MODEL,\n",
    "    input_size=INPUT_SIZE,\n",
    "    mask_ratio=MASK_RATIO,\n",
    "    norm_pix_loss=NORM_PIX_LOSS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    lr=LR,\n",
    "    blr=BLR,\n",
    "    min_lr=MIN_LR,\n",
    "    warmup_epochs=WARMUP_EPOCHS,\n",
    "    data_path=DATA_PATH,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    resume=RESUME,\n",
    "    start_epoch=START_EPOCH,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_mem=PIN_MEM,\n",
    "    world_size=WORLD_SIZE,\n",
    "    local_rank=LOCAL_RANK,\n",
    "    dist_on_itp=DIST_ON_ITP,\n",
    "    dist_url=DIST_URL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n"
     ]
    }
   ],
   "source": [
    "misc.init_distributed_mode(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:01:06.230455] job dir: /home/user/Schreibtisch/projects/git_data/segmentation_test/nbs\n"
     ]
    }
   ],
   "source": [
    "print('job dir: {}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(args.device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the seed for reproducibility\n",
    "seed = args.seed + misc.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple augmentation\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(\n",
    "                args.input_size, \n",
    "                scale=(0.2, 1.0), \n",
    "                interpolation=3),  # 3 is bicubic\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = datasets.ImageFolder(\n",
    "    os.path.join(\n",
    "        args.data_path, 'train'), \n",
    "        transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 14669\n",
       "    Root location: /home/user/.fastai/data/imagewang-160/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=True)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:01:11.562099] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x76348e6be190>\n"
     ]
    }
   ],
   "source": [
    "if True:  # args.distributed:\n",
    "    num_tasks = misc.get_world_size()\n",
    "    global_rank = misc.get_rank()\n",
    "    sampler_train = torch.utils.data.DistributedSampler(\n",
    "        dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "    )\n",
    "    print(\"Sampler_train = %s\" % str(sampler_train))\n",
    "else:\n",
    "    sampler_train = torch.utils.data.RandomSampler(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if global_rank == 0 and args.log_dir is not None:\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "else:\n",
    "    log_writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mae_vit_large_patch16'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedAutoencoderViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (decoder_blocks): ModuleList(\n",
       "    (0-7): 8 x Block(\n",
       "      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (decoder_pred): Linear(in_features=512, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define the model\n",
    "model = models_mae.__dict__[args.model](norm_pix_loss=args.norm_pix_loss)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "model_without_ddp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    # Your main function implementation here\n",
    "    print(\"Starting MAE pre-training with the following arguments:\")\n",
    "    for arg, value in vars(args).items():\n",
    "        print(f\"{arg}: {value}\")\n",
    "    \n",
    "    # Add your training logic here\n",
    "    # For example:\n",
    "    # model = create_model(args)\n",
    "    # dataset = load_dataset(args)\n",
    "    # train_one_epoch(model, dataset, args)\n",
    "    \n",
    "    print(\"MAE pre-training completed.\")\n",
    "\n",
    "# To run the main function, you can now use:\n",
    "# main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
