{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pytorch dataset will be created here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataloader_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from PIL import Image\n",
    "from typing import List, Callable, Tuple, Dict, Union\n",
    "from pathlib import Path\n",
    "from fastcore.all import *\n",
    "import cv2\n",
    "import torch\n",
    "from fastcore.all import *\n",
    "from fastcore.foundation import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            #A.Resize(256, 256),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            #A.Resize(256, 256),\n",
    "            A.Normalize(mean=[0, 0, 0], std=[1/255, 1/255, 1/255]),\n",
    "            #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from cv_tools.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "                self, \n",
    "                image_path:Union[Path, str],\n",
    "                mask_path:Union[Path, str],\n",
    "                transform=None,\n",
    "                exts='.png'\n",
    "                ):\n",
    "        # getting images and masks\n",
    "        self.image_path = Path(image_path)\n",
    "        self.mask_path = Path(mask_path)\n",
    "        self.transform = transform\n",
    "        self.images = Path(self.image_path).ls(file_exts=exts)\n",
    "        self.masks = Path(self.mask_path).ls(file_exts=exts)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_fn = self.images[idx]\n",
    "        # Assuming the mask file name is same as image file name\n",
    "        name_ = Path(image_fn).name\n",
    "        image = cv2.imread(f\"{image_fn}\", cv2.IMREAD_GRAYSCALE)\n",
    "        mask_fn = Path(self.mask_path, name_)\n",
    "\n",
    "        mask = cv2.imread(f\"{mask_fn}\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('n:/homes/hasan/easy_front/easy-front-pin-detection/nbs')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_path= Path(r'm:/data/projects/easy_front_detection/eberhard_data')\n",
    "im_path = f'{root_path}/images'\n",
    "mask_path = f'{root_path}/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 68)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = int(TRAIN_SPLIT *len(dataset))\n",
    "val_len = len(dataset) - train_len\n",
    "train_len, val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,\n",
    "    lengths=[train_len, val_len]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 68)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def repeat_collate_fn(batch, batch_size=4):\n",
    "    images, masks = zip(*batch)\n",
    "\n",
    "    images = list(images)\n",
    "    masks = list(masks)\n",
    "\n",
    "    num_to_add = batch_size - len(images)\n",
    "    if num_to_add > 0:\n",
    "        for i in range(num_to_add):\n",
    "            index = i%len(images)\n",
    "            images.append(images[index])\n",
    "            masks.append(masks[index])\n",
    "    return torch.stack(images), torch.stack(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_pytorch_dataloader(\n",
    "    split_type:str, # in case of 'random' randomly data will be splitted\n",
    "    split_per:float, # percentage of training data\n",
    "    batch_size:int,\n",
    "    image_path:Union[Path, str],\n",
    "    mask_path:Union[Path, str],\n",
    "    trn_transforms:Callable, # a callable function trn_transforms \n",
    "    val_transforms:Callable, # a callable function val_transforms\n",
    "    exts:str='.png',  # image  and mask data extensions\n",
    "    collate_fn:Callable=repeat_collate_fn,\n",
    "    num_workers:str=4\n",
    "   ):\n",
    "\n",
    "    'Create pytorch dataloader based on the argument'\n",
    "\n",
    "    full_dataset = SegmentationDataset(\n",
    "                                image_path=image_path,\n",
    "                                mask_path=mask_path,\n",
    "                                exts=exts\n",
    "                              )\n",
    "\n",
    "    print(f' Number of images found = {len(full_dataset)}')\n",
    "    if split_type == 'random':\n",
    "        train_len = int(split_per * len(full_dataset))\n",
    "        val_len = len(full_dataset) - train_len\n",
    "\n",
    "\n",
    "        indices = torch.randperm(len(full_dataset)).tolist()\n",
    "        train_indices, val_indices = indices[:train_len], indices[train_len:]\n",
    "\n",
    "        train_ds = Subset(full_dataset, train_indices)\n",
    "        val_ds = Subset(full_dataset, val_indices)\n",
    "\n",
    "\n",
    "        #train_ds, val_ds = random_split(dataset, lengths=[train_len, val_len])\n",
    "        print(f' training dataset length = {len(train_ds)} and validation dataset length=  {len(val_ds)}')\n",
    "        \n",
    "\n",
    "        train_ds.dataset.transform = trn_transforms\n",
    "        val_ds.dataset.transform = val_transforms\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "                              train_ds, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True, \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True,\n",
    "                              collate_fn=collate_fn\n",
    "        )\n",
    "        val_dl = DataLoader(\n",
    "                              val_ds, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False, \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=True,\n",
    "                              collate_fn=collate_fn\n",
    "        )\n",
    "        return train_dl, val_dl\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only random split is implemented\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#339) [Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_0_A.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_0_B.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_10_A.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_10_B.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_11_A.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_11_B.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_12_A.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_12_B.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_13_A.png'),Path('m:/data/projects/easy_front_detection/eberhard_data/images/0_0_CroppedImg_20231018_92042317_13_B.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(im_path).ls(file_exts='.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of images found = 339\n",
      " training dataset length = 271 and validation dataset length=  68\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = create_pytorch_dataloader(\n",
    "    split_type='random',\n",
    "    split_per=0.8,\n",
    "    batch_size=2,\n",
    "    image_path=im_path,\n",
    "    mask_path=mask_path,\n",
    "    transforms=None,\n",
    "    num_workers=0,\n",
    "    collate_fn=repeat_collate_fn\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def visualize_batch(images, masks, num_images=4):\n",
    "    fig, axs = plt.subplots(1,num_images, figsize=(5, num_images*5))\n",
    "    for idx, (image, mask) in enumerate(zip(images, masks)):\n",
    "        if idx >= num_images:\n",
    "            break\n",
    "        axs[idx].imshow(image.permute(1, 2, 0)[:,:,0], cmap='gray')\n",
    "        axs[idx].imshow(mask.squeeze(), cmap='jet', alpha=0.3)  # overlay mask on image\n",
    "        axs[idx].axis('off')\n",
    "        axs[idx].set_title('Image with Mask')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_dl\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#visualize_batch(images=images, masks=masks, num_images=2)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "images, masks = next(iter(train_dl))\n",
    "#visualize_batch(images=images, masks=masks, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export('09_dataset_creation.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
